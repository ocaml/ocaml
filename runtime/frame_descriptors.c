#define CAML_INTERNALS

#include "frame_descriptors.h"
#include "caml/platform.h"
#include "caml/major_gc.h" /* for caml_major_cycles_completed */
#include "caml/memory.h"
#include <stddef.h>

/* Defined in code generated by ocamlopt */
extern intnat * caml_frametable[];

typedef struct link {
  intnat* frametable;
  struct link *next;
} link;

#define iter_list(list,lnk) \
  for (lnk = list; lnk != NULL; lnk = lnk->next)

caml_frame_descrs build_frame_descriptors(link* frametables)
{
  intnat num_descr, tblsize, i, j, len;
  intnat * tbl;
  frame_descr * d;
  uintnat nextd;
  uintnat h;
  link *lnk;
  caml_frame_descrs table;

  /* Count the frame descriptors */
  num_descr = 0;
  iter_list(frametables,lnk) {
    num_descr += *lnk->frametable;
  }

  /* The size of the hashtable is a power of 2 greater or equal to
     2 times the number of descriptors */
  tblsize = 4;
  while (tblsize < 2 * num_descr) tblsize *= 2;

  /* Allocate the hash table */
  table.descriptors = caml_stat_alloc(tblsize * sizeof(frame_descr*));
  table.mask = tblsize - 1;
  for (i = 0; i < tblsize; i++) table.descriptors[i] = NULL;

  /* Fill the hash table */
  iter_list(frametables,lnk) {
    tbl = lnk->frametable;
    len = *tbl;
    d = (frame_descr *)(tbl + 1);
    for (j = 0; j < len; j++) {
      h = Hash_retaddr(d->retaddr, tblsize - 1);
      while (table.descriptors[h] != NULL) {
        h = (h+1) & table.mask;
      }
      table.descriptors[h] = d;
      nextd =
        ((uintnat)d +
         sizeof(char *) + sizeof(short) + sizeof(short) +
         sizeof(short) * d->num_live + sizeof(frame_descr *) - 1)
        & -sizeof(frame_descr *);
      if (d->frame_size & 1 &&
          d->frame_size != (unsigned short)-1) {
        nextd += 8;
      }
      d = (frame_descr *) nextd;
    }
  }
  return table;
}

static caml_plat_mutex descr_mutex;
static link* frametables;

/* Memory used by frametables is only freed once a GC cycle has
   completed, because other threads access the frametable at
   unpredictable times. */
struct frametable_version {
  caml_frame_descrs table;

  /* after this cycle has completed,
     the previous table should be deallocated.
     Set to No_need_to_free after prev is freed */
  atomic_uintnat free_prev_after_cycle;
  struct frametable_version* prev;
};
#define No_need_to_free ((uintnat)(-1))

/* Only modified when holding descr_mutex, but read without locking */
static atomic_uintnat current_frametable = ATOMIC_UINTNAT_INIT(0);

static link *cons(intnat *frametable, link *tl) {
  link *lnk = caml_stat_alloc(sizeof(link));
  lnk->frametable = frametable;
  lnk->next = tl;
  return lnk;
}

void caml_init_frame_descriptors(void)
{
  int i;
  struct frametable_version *ft;

  caml_plat_mutex_init(&descr_mutex);

  caml_plat_lock(&descr_mutex);
  for (i = 0; caml_frametable[i] != 0; i++)
    frametables = cons(caml_frametable[i], frametables);

  ft = caml_stat_alloc(sizeof(*ft));
  ft->table = build_frame_descriptors(frametables);
  atomic_store_rel(&ft->free_prev_after_cycle, No_need_to_free);
  ft->prev = 0;
  atomic_store_rel(&current_frametable, (uintnat)ft);
  caml_plat_unlock(&descr_mutex);
}

void caml_register_frametable(intnat *table)
{
  struct frametable_version *ft, *old;

  caml_plat_lock(&descr_mutex);

  frametables = cons(table, frametables);
  old = (struct frametable_version*)atomic_load_acq(&current_frametable);
  CAMLassert(old != NULL);
  ft = caml_stat_alloc(sizeof(*ft));
  ft->table = build_frame_descriptors(frametables);
  atomic_store_rel(&ft->free_prev_after_cycle, caml_major_cycles_completed);
  ft->prev = old;
  atomic_store_rel(&current_frametable, (uintnat)ft);

  caml_plat_unlock(&descr_mutex);
}

caml_frame_descrs caml_get_frame_descrs()
{
  struct frametable_version *ft =
    (struct frametable_version*)atomic_load_acq(&current_frametable);
  CAMLassert(ft);
  if (atomic_load_acq(&ft->free_prev_after_cycle) < caml_major_cycles_completed) {
    /* it's now safe to free the old table */
    caml_plat_lock(&descr_mutex);
    if (ft->prev != NULL) {
      caml_stat_free(ft->prev->table.descriptors);
      caml_stat_free(ft->prev);
      ft->prev = NULL;
      atomic_store_rel(&ft->free_prev_after_cycle, No_need_to_free);
    }
    caml_plat_unlock(&descr_mutex);
  }
  return ft->table;
}

frame_descr* caml_find_frame_descr(caml_frame_descrs fds, uintnat pc)
{
  frame_descr * d;
  uintnat h;

  h = Hash_retaddr(pc, fds.mask);
  while (1) {
    d = fds.descriptors[h];
    if (d == 0) return NULL; /* can happen if some code compiled without -g */
    if (d->retaddr == pc) break;
    h = (h+1) & fds.mask;
  }
  return d;
}
